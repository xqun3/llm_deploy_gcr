{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DeepSeek-R1 series on SageMaker vLLM endpoint example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Define some variables\n",
    "\n",
    "The byoc will build and store a vllm endpoint docker image in you ECR private repo (for example `sagemaker_endpoint/vllm`), you need to define the following variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please choose model and instances from above setting ⬆️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"tsbiosky/gemma3-hok-pubg-merge\"\n",
    "INSTANCE_TYPE = \"ml.g5.12xlarge\"\n",
    "\n",
    "# better to work with vllm>=v0.7.3\n",
    "VLLM_VERSION = \"v0.8.3\"\n",
    "REPO_NAMESPACE = \"sagemaker_endpoint/vllm\"\n",
    "ACCOUNT = !aws sts get-caller-identity --query Account --output text\n",
    "REGION = !aws configure get region\n",
    "ACCOUNT = ACCOUNT[0]\n",
    "REGION = REGION[0]\n",
    "if REGION.startswith(\"cn\"):\n",
    "    # this is a container mirror in cn region: https://github.com/nwcdlabs/container-mirror\n",
    "    VLLM_REPO = \"048912060910.dkr.ecr.cn-northwest-1.amazonaws.com.cn/dockerhub/vllm/vllm-openai\"\n",
    "    CONTAINER = f\"{ACCOUNT}.dkr.ecr.{REGION}.amazonaws.com.cn/{REPO_NAMESPACE}:{VLLM_VERSION}\"\n",
    "else:\n",
    "    VLLM_REPO = \"vllm/vllm-openai\"\n",
    "    CONTAINER = f\"{ACCOUNT}.dkr.ecr.{REGION}.amazonaws.com/{REPO_NAMESPACE}:{VLLM_VERSION}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build the container\n",
    "\n",
    "Endpoint starting codes are in `app/`. The script will build and push to ecr. \n",
    "\n",
    "**The docker only need to be built once**, and after that, when deploying other endpoints, the same docker image can be shared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runging:\n",
      " VLLM_REPO=vllm/vllm-openai VLLM_VERSION=v0.8.3 REPO_NAMESPACE=sagemaker_endpoint/vllm ACCOUNT=596899493901 REGION=us-east-1 bash ./build_and_push.sh \n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "596899493901.dkr.ecr.us-east-1.amazonaws.com/sagemaker_endpoint/vllm:v0.8.3\n",
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                          docker:default\n",
      "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.1s (2/2)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.8.3         0.1s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.2s (9/9) FINISHED                                 docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.8.3         0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.8.3@sha256:4d8d397a62c362372  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 134B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/4] COPY app/ /app                                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper re  0.0s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     0.0s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:6a52fb9c559a8a83bfde4c5d883f3d3bb88b113b2d2ff  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/sagemaker_endpoint/vllm:v0.8.3                  0.0s\n",
      "\u001b[0m\u001b[?25hThe push refers to repository [596899493901.dkr.ecr.us-east-1.amazonaws.com/sagemaker_endpoint/vllm]\n",
      "\n",
      "\u001b[1Be7df50a0: Preparing \n",
      "\u001b[1Bd0bb6215: Preparing \n",
      "\u001b[1B54e0bac9: Preparing \n",
      "\u001b[1B4f28a1cd: Preparing \n",
      "\u001b[1B774fe212: Preparing \n",
      "\u001b[1Bfde7f2fe: Preparing \n",
      "\u001b[1B34d12c85: Preparing \n",
      "\u001b[1B903a0de2: Preparing \n",
      "\u001b[1Bc6ff08a5: Preparing \n",
      "\u001b[1B1a8f2108: Preparing \n",
      "\u001b[1B579ca14c: Preparing \n",
      "\u001b[1B42d1a68b: Preparing \n",
      "\u001b[1Bd8604c52: Preparing \n",
      "\u001b[1B08982790: Preparing \n",
      "\u001b[1Bbd223cc5: Preparing \n",
      "\u001b[1Ba4451161: Preparing \n",
      "\u001b[1B6886a648: Preparing \n",
      "\u001b[1Baf1ca5c5: Preparing \n",
      "\u001b[1Be921ad1f: Preparing \n",
      "\u001b[1B0f301880: Preparing \n",
      "\u001b[1B5b38d6e0: Preparing \n",
      "\u001b[1B261d196e: Preparing \n",
      "\u001b[1B315df33c: Preparing \n",
      "\u001b[1Bf74291b2: Preparing \n",
      "\u001b[1B07952594: Preparing \n",
      "\u001b[1Be8c22f69: Layer already exists \u001b[23A\u001b[2K\u001b[21A\u001b[2K\u001b[16A\u001b[2K\u001b[11A\u001b[2K\u001b[6A\u001b[2K\u001b[2A\u001b[2Kv0.8.3: digest: sha256:6c4691ae475ebe2beacd77423e82825c38befcdf67d428c5ca3068b5ecb12674 size: 5780\n"
     ]
    }
   ],
   "source": [
    "cmd = f\"VLLM_REPO={VLLM_REPO} VLLM_VERSION={VLLM_VERSION} REPO_NAMESPACE={REPO_NAMESPACE} ACCOUNT={ACCOUNT} REGION={REGION} bash ./build_and_push.sh \"\n",
    "print(\"Runging:\\n\", cmd)\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deploy on SageMaker\n",
    "\n",
    "define the model and deploy on SageMaker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.37.29)\n",
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.243.0)\n",
      "Requirement already satisfied: transformers in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (4.51.1)\n",
      "Requirement already satisfied: huggingface_hub in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.30.2)\n",
      "Requirement already satisfied: modelscope in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.24.1)\n",
      "Collecting s5cmd\n",
      "  Downloading s5cmd-0.2.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting hf_transfer\n",
      "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting sagemaker-ssh-helper\n",
      "  Downloading sagemaker_ssh_helper-2.3.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: botocore<1.38.0,>=1.37.29 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3) (1.37.29)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3) (0.11.2)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (23.2.0)\n",
      "Requirement already satisfied: cloudpickle>=2.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (3.1.1)\n",
      "Requirement already satisfied: docker in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (7.1.0)\n",
      "Requirement already satisfied: fastapi in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.115.8)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (6.11.0)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.23.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.26.4)\n",
      "Requirement already satisfied: omegaconf<=2.3,>=2.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (21.3)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.2.3)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.3.3)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.3.6)\n",
      "Requirement already satisfied: protobuf<6.0,>=3.12 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (5.29.3)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (6.1.1)\n",
      "Requirement already satisfied: pyyaml~=6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.32.3)\n",
      "Requirement already satisfied: sagemaker-core<2.0.0,>=1.0.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.0.22)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.7.7)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (3.0.0)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.67.1)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.3.0)\n",
      "Requirement already satisfied: uvicorn in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.34.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub) (2025.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore<1.38.0,>=1.37.29->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.21.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from omegaconf<=2.3,>=2.2->sagemaker) (4.9.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->sagemaker) (3.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->sagemaker) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->sagemaker) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->sagemaker) (2025.1.31)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker) (2.10.6)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker) (13.9.4)\n",
      "Requirement already satisfied: mock<5.0,>4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker) (4.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.22.3)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from fastapi->sagemaker) (0.45.3)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from google-pasta->sagemaker) (1.17.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->sagemaker) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->sagemaker) (2025.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (1.7.6.9)\n",
      "Requirement already satisfied: dill>=0.3.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.9)\n",
      "Requirement already satisfied: pox>=0.3.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.5)\n",
      "Requirement already satisfied: multiprocess>=0.70.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.70.17)\n",
      "Requirement already satisfied: click>=7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from uvicorn->sagemaker) (8.1.8)\n",
      "Requirement already satisfied: h11>=0.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from uvicorn->sagemaker) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (2.27.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (2.19.1)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from starlette<0.46.0,>=0.40.0->fastapi->sagemaker) (4.8.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi->sagemaker) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi->sagemaker) (1.3.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (0.1.2)\n",
      "Downloading s5cmd-0.2.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m112.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m146.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sagemaker_ssh_helper-2.3.0-py3-none-any.whl (102 kB)\n",
      "Installing collected packages: s5cmd, hf_transfer, sagemaker-ssh-helper\n",
      "Successfully installed hf_transfer-0.1.9 s5cmd-0.2.0 sagemaker-ssh-helper-2.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U boto3 sagemaker transformers huggingface_hub modelscope s5cmd hf_transfer sagemaker-ssh-helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.1 Init SageMaker session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/09/25 06:53:19] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/09/25 06:53:19]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=763781;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=762495;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=130715;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=618639;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=189952;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=63961;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/09/25 06:53:20] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/09/25 06:53:20]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=475864;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=873221;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import Model\n",
    "from sagemaker_ssh_helper.wrapper import SSHModelWrapper \n",
    "\n",
    "\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "default_bucket = sess.default_bucket()\n",
    "\n",
    "sagemaker_client = boto3.client(\"sagemaker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Download and upload model file\n",
    "\n",
    "Firstly, you need to prepare model weights and upload to S3. You can download from HuggingFace, ModelScope or upload your own model. \n",
    "\n",
    "If you want vllm to automatically pull the model when it starts, this step can be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_model_path: ./models/tsbiosky-gemma3-hok-pubg-merge\n"
     ]
    }
   ],
   "source": [
    "model_name = MODEL_ID.replace(\"/\", \"-\").replace(\".\", \"-\")\n",
    "local_model_path = \"./models/\" + model_name\n",
    "s3_model_path = f\"s3://{default_bucket}/models/\" + model_name\n",
    "\n",
    "%mkdir -p code {local_model_path}\n",
    "\n",
    "print(\"local_model_path:\", local_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Option 1: Global region (download from HuggingFace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading '.gitattributes' to 'models/tsbiosky-gemma3-hok-pubg-merge/.cache/huggingface/download/wPaCkH-WbT7GsmxMKKrNZTV4nSM=.52373fe24473b1aa44333d318f578ae6bf04b49b.incomplete'\n",
      ".gitattributes: 100%|██████████████████████| 1.57k/1.57k [00:00<00:00, 10.5MB/s]\n",
      "Download complete. Moving file to models/tsbiosky-gemma3-hok-pubg-merge/.gitattributes\n",
      "Downloading 'README.md' to 'models/tsbiosky-gemma3-hok-pubg-merge/.cache/huggingface/download/Xn7B-BWUGOee2Y6hCZtEhtFu4BE=.bcb9ac1ec89467d0ae13f2383af8d2eefd3862fe.incomplete'\n",
      "README.md: 100%|███████████████████████████████| 903/903 [00:00<00:00, 12.7MB/s]\n",
      "Download complete. Moving file to models/tsbiosky-gemma3-hok-pubg-merge/README.md\n",
      "Downloading 'added_tokens.json' to 'models/tsbiosky-gemma3-hok-pubg-merge/.cache/huggingface/download/SeqzFlf9ZNZ3or_wZAOIdsM3Yxw=.e17bde03d42feda32d1abfca6d3b598b9a020df7.incomplete'\n",
      "added_tokens.json: 100%|██████████████████████| 35.0/35.0 [00:00<00:00, 275kB/s]\n",
      "Download complete. Moving file to models/tsbiosky-gemma3-hok-pubg-merge/added_tokens.json\n",
      "Downloading 'config.json' to 'models/tsbiosky-gemma3-hok-pubg-merge/.cache/huggingface/download/8_PA_wEVGiVa2goH2H4KQOQpvVY=.c7538773d48531b4c2a07491162a53458461b819.incomplete'\n",
      "config.json: 100%|█████████████████████████████| 930/930 [00:00<00:00, 13.6MB/s]\n",
      "Download complete. Moving file to models/tsbiosky-gemma3-hok-pubg-merge/config.json\n",
      "Downloading 'mergekit_config.yml' to 'models/tsbiosky-gemma3-hok-pubg-merge/.cache/huggingface/download/J3ZbAnNdhsFXLpOzduCARVDOur8=.4fce845669c78e6bda04b99a99763239e902a0e0.incomplete'\n",
      "mergekit_config.yml: 100%|█████████████████████| 187/187 [00:00<00:00, 2.93MB/s]\n",
      "Download complete. Moving file to models/tsbiosky-gemma3-hok-pubg-merge/mergekit_config.yml\n",
      "Downloading 'model-00001-of-00011.safetensors' to 'models/tsbiosky-gemma3-hok-pubg-merge/.cache/huggingface/download/JPIYbabm4vDoeFTrDUtltbMIGtA=.ef2d35e3f1d5de764564115ea4d575d0794b2be6d1ed0c9b4006633adfa0a002.incomplete'\n",
      "model-00001-of-00011.safetensors: 100%|████▉| 4.93G/4.93G [00:07<00:00, 623MB/s]\n",
      "Download complete. Moving file to models/tsbiosky-gemma3-hok-pubg-merge/model-00001-of-00011.safetensors\n",
      "Downloading 'model-00002-of-00011.safetensors' to 'models/tsbiosky-gemma3-hok-pubg-merge/.cache/huggingface/download/zZDuRV0o1YzR-FfEq_7s8RO5vjE=.960b8091951ebc8e7028bfbceb890418da5c03891a9862cde66f47adfc3110b2.incomplete'\n",
      "model-00002-of-00011.safetensors:   0%|             | 0.00/4.95G [00:00<?, ?B/s]^C\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n",
    "\n",
    "!huggingface-cli download --resume-download {MODEL_ID} --local-dir {local_model_path} --max-workers 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Option 2: China region  (download from ModelScope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !modelscope download --local_dir {local_model_path} {MODEL_ID} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### upload to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!s5cmd sync --concurrency 32 {local_model_path}/ {s3_model_path}/\n",
    "print(\"s3_model_path:\", s3_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.3 Prepare vllm start scripts\n",
    "\n",
    "Then you need to a write the vllm starting scripts for endpoint, the container will automatically use the `start.sh` as the entrypont.\n",
    "\n",
    "Please carefully modify the startup script file as needed, such as the model running parameter information. All parameters can be referenced at [https://docs.vllm.ai/en/latest/serving/openai_compatible_server.html](https://docs.vllm.ai/en/latest/serving/openai_compatible_server.html)\n",
    "\n",
    "Here is a simple script that pulling a model from S3 and starting a vllm server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_model_path=\"s3://sagemaker-us-east-1-596899493901/models/tsbiosky-gemma3-hok-pubg-merge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_code_path: tsbiosky-gemma3-hok-pubg-merge-250409-0653\n"
     ]
    }
   ],
   "source": [
    "endpoint_model_name = sagemaker.utils.name_from_base(model_name, short=True)\n",
    "local_code_path = endpoint_model_name\n",
    "vllm_metrics_interval = 10\n",
    "s3_code_path = f\"s3://{default_bucket}/endpoint_code/vllm_byoc/{endpoint_model_name}.tar.gz\"\n",
    "\n",
    "%mkdir -p {local_code_path}\n",
    "\n",
    "print(\"local_code_path:\", local_code_path)\n",
    "\n",
    "with open(f\"{local_code_path}/start.sh\", \"w\") as f:\n",
    "    f.write(f\"\"\"\n",
    "#!/bin/bash\n",
    "\n",
    "# download model to local\n",
    "s5cmd sync --concurrency 64 \\\n",
    "    {s3_model_path}/* /temp/model_weight\n",
    "\n",
    "\n",
    "# the start script need to be adjust as you needed\n",
    "# port needs to be $SAGEMAKER_BIND_TO_PORT\n",
    "\n",
    "python3 -m vllm.entrypoints.openai.api_server \\\\\n",
    "    --port $SAGEMAKER_BIND_TO_PORT \\\\\n",
    "    --trust-remote-code --gpu-memory-utilization 0.90 \\\\\n",
    "    --tensor-parallel-size 4 \\\\\n",
    "    --max_num_seqs 4 \\\\\n",
    "    --max-model-len 4096 \\\\\n",
    "    --dtype bfloat16 \\\\\n",
    "    --served-model-name {MODEL_ID} \\\\\n",
    "    --model /temp/model_weight\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tsbiosky-gemma3-hok-pubg-merge-250409-0653/\n",
      "tsbiosky-gemma3-hok-pubg-merge-250409-0653/start.sh\n",
      "upload: ./tsbiosky-gemma3-hok-pubg-merge-250409-0653.tar.gz to s3://sagemaker-us-east-1-596899493901/endpoint_code/vllm_byoc/tsbiosky-gemma3-hok-pubg-merge-250409-0653.tar.gz\n",
      "s3_code_path: s3://sagemaker-us-east-1-596899493901/endpoint_code/vllm_byoc/tsbiosky-gemma3-hok-pubg-merge-250409-0653.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!rm -f {local_code_path}.tar.gz\n",
    "!tar czvf {local_code_path}.tar.gz {local_code_path}/\n",
    "!aws s3 cp {local_code_path}.tar.gz {s3_code_path}\n",
    "print(\"s3_code_path:\", s3_code_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.3 Deploy endpoint on SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ModelArn': 'arn:aws:sagemaker:us-east-1:596899493901:model/tsbiosky-gemma3-hok-pubg-merge-250409-0653', 'ResponseMetadata': {'RequestId': 'b4a797e0-a498-401f-95ee-ae9b51be1788', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'b4a797e0-a498-401f-95ee-ae9b51be1788', 'content-type': 'application/x-amz-json-1.1', 'content-length': '104', 'date': 'Wed, 09 Apr 2025 06:53:56 GMT'}, 'RetryAttempts': 0}}\n",
      "endpoint_model_name: tsbiosky-gemma3-hok-pubg-merge-250409-0653\n"
     ]
    }
   ],
   "source": [
    "# Step 0. create model\n",
    "\n",
    "# endpoint_model_name already defined in above step\n",
    "\n",
    "variant_name = \"AllTrafic\"\n",
    "\n",
    "create_model_response = sagemaker_client.create_model(\n",
    "    ModelName=endpoint_model_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    PrimaryContainer={\n",
    "        \"Image\": CONTAINER,\n",
    "        \"ModelDataUrl\": s3_code_path,\n",
    "        \"Environment\": {\n",
    "            \"ENDPOINT_NAME\": endpoint_model_name,\n",
    "            \"VARIANT_NAME\": variant_name,\n",
    "            \"VLLM_METRICS_INTERVAL\": str(vllm_metrics_interval),\n",
    "        },\n",
    "    },\n",
    ")\n",
    "print(create_model_response)\n",
    "print(\"endpoint_model_name:\", endpoint_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EndpointConfigArn': 'arn:aws:sagemaker:us-east-1:596899493901:endpoint-config/tsbiosky-gemma3-hok-pubg-merge-250409-0653', 'ResponseMetadata': {'RequestId': 'd4bc5a5b-c7a2-4e93-b26c-ee9ffd403af3', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'd4bc5a5b-c7a2-4e93-b26c-ee9ffd403af3', 'content-type': 'application/x-amz-json-1.1', 'content-length': '123', 'date': 'Wed, 09 Apr 2025 06:53:58 GMT'}, 'RetryAttempts': 0}}\n",
      "endpoint_config_name: tsbiosky-gemma3-hok-pubg-merge-250409-0653\n"
     ]
    }
   ],
   "source": [
    "# Step 1. create endpoint config\n",
    "\n",
    "# endpoint_config_name = sagemaker.utils.name_from_base(model_name, short=True)\n",
    "endpoint_config_name = endpoint_model_name\n",
    "\n",
    "endpoint_config_response = sagemaker_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": variant_name,\n",
    "            \"ModelName\": endpoint_model_name,\n",
    "            \"InstanceType\": INSTANCE_TYPE,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ContainerStartupHealthCheckTimeoutInSeconds\": 1000,\n",
    "            # \"EnableSSMAccess\": True,\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(endpoint_config_response)\n",
    "print(\"endpoint_config_name:\", endpoint_config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EndpointArn': 'arn:aws:sagemaker:us-east-1:596899493901:endpoint/tsbiosky-gemma3-hok-pubg-merge-250409-0653', 'ResponseMetadata': {'RequestId': '70738ad1-91b1-4364-b310-25f711ce4c58', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '70738ad1-91b1-4364-b310-25f711ce4c58', 'content-type': 'application/x-amz-json-1.1', 'content-length': '110', 'date': 'Wed, 09 Apr 2025 06:54:01 GMT'}, 'RetryAttempts': 0}}\n",
      "20250409-06:54:01 status: Creating\n",
      "20250409-06:55:01 status: Creating\n",
      "20250409-06:56:02 status: Creating\n",
      "20250409-06:57:02 status: Creating\n",
      "20250409-06:58:02 status: Creating\n",
      "20250409-06:59:02 status: Creating\n",
      "20250409-07:00:02 status: Creating\n",
      "20250409-07:01:02 status: Creating\n",
      "20250409-07:02:02 status: Creating\n",
      "20250409-07:03:03 status: Creating\n",
      "Endpoint: tsbiosky-gemma3-hok-pubg-merge-250409-0653 InService\n"
     ]
    }
   ],
   "source": [
    "# Step 2. create endpoint\n",
    "\n",
    "# endpoint_name = sagemaker.utils.name_from_base(model_name, short=True)\n",
    "endpoint_name = endpoint_model_name\n",
    "\n",
    "create_endpoint_response = sagemaker_client.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "print(create_endpoint_response)\n",
    "\n",
    "while 1:\n",
    "    status = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)[\"EndpointStatus\"]\n",
    "    if status != \"Creating\":\n",
    "        break\n",
    "    print(datetime.now().strftime('%Y%m%d-%H:%M:%S') + \" status: \" + status)\n",
    "    time.sleep(60)\n",
    "print(\"Endpoint:\", endpoint_name, status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test\n",
    "\n",
    "You can invoke your model with SageMaker runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# messages = [{\n",
    "#     \"role\": \"user\",\n",
    "#     \"content\": \"Hi, who are you!\"\n",
    "# }]\n",
    "prompt=\"<role>You're a specialist in meticulously translating chat text from FPS game PUBG.</role>\\n<task> translate user chat text input to English</task>\\n<requirements>\\n1.return only translation results \\n2.Identify and translate gaming terminology with terminology example\\n3.Strict following the terminology example.\\n4.Keep game communication concise\\n5.Retain tags <lock_1> and <newline>\\n6.Retain gibberish\\n</requirements>\\n<terminology example>text:任务\\ntranslation:Mission\\n</terminology example>\\n<output_format>\\nOutput only one final translation result without any thought process or explanation.\\n</output_format>\\n\"\n",
    "text=\"完成1-9级所有任务\"\n",
    "    \n",
    "messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": text\n",
    "        }\n",
    "]\n",
    "max_tokens = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Message api non-stream mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete all missions from level 1-9<end_of_turn>\n"
     ]
    }
   ],
   "source": [
    "sagemaker_runtime = boto3.client('runtime.sagemaker')\n",
    "\n",
    "payload = {\n",
    "    \"model\": MODEL_ID,\n",
    "    \"messages\": messages,\n",
    "    \"max_tokens\": max_tokens,\n",
    "    \"stream\": False\n",
    "}\n",
    "response = sagemaker_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "print(json.loads(response['Body'].read())[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.2 Message api stream mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete all missions from levels 1-9<end_of_turn>\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"model\": MODEL_ID,\n",
    "    \"messages\": messages,\n",
    "    \"max_tokens\": max_tokens,\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "response = sagemaker_runtime.invoke_endpoint_with_response_stream(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "buffer = \"\"\n",
    "for t in response['Body']:\n",
    "    buffer += t[\"PayloadPart\"][\"Bytes\"].decode()\n",
    "    last_idx = 0\n",
    "    for match in re.finditer(r'^data:\\s*(.+?)(\\n\\n)', buffer):\n",
    "        try:\n",
    "            data = json.loads(match.group(1).strip())\n",
    "            last_idx = match.span()[1]\n",
    "            print(data[\"choices\"][0][\"delta\"][\"content\"], end=\"\")\n",
    "        except (json.JSONDecodeError, KeyError, IndexError) as e:\n",
    "            pass\n",
    "    buffer = buffer[last_idx:]\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Speed test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好的，这是一首介绍上海的七言律诗：\n",
      "\n",
      "黄浦江流绕九重天，\n",
      "魔都繁华耀眼帘。\n",
      "外滩钟声传古韵，\n",
      "陆家嘴立展新颜。\n",
      "石库门里寻旧梦，\n",
      "豫园庭院赏花妍。\n",
      "海纳百川容万象，\n",
      "东方明珠璀璨鲜。\n",
      "<end_of_turn>{'id': 'chatcmpl-723ac698fa6b40919e7f2573ac8de89a', 'object': 'chat.completion.chunk', 'created': 1744183147, 'model': 'tsbiosky/gemma3-hok-pubg-merge', 'choices': [], 'usage': {'prompt_tokens': 20, 'total_tokens': 107, 'completion_tokens': 87}}\n",
      "\n",
      "==================================================\n",
      "Input_tokens 20 Output_tokens 87\n",
      "First token latency 0.0558 seconds\n",
      "Output speed 26.7 tokens/seconds\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sagemaker_runtime = boto3.client('runtime.sagemaker')\n",
    "\n",
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"帮我写一首七言律诗介绍上海\"\n",
    "}]\n",
    "\n",
    "payload = {\n",
    "    \"model\": MODEL_ID,\n",
    "    \"messages\": messages,\n",
    "    \"max_tokens\": 1024,\n",
    "    \"temperature\": 0.0,\n",
    "    \"stream\": True,\n",
    "    \"stream_options\": {\"include_usage\": True},\n",
    "}\n",
    "endpoint_name=endpoint_model_name\n",
    "response = sagemaker_runtime.invoke_endpoint_with_response_stream(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "buffer = \"\"\n",
    "time_start = time.time()\n",
    "first_token_latency = 0\n",
    "output = []\n",
    "for t in response['Body']:\n",
    "    buffer += t[\"PayloadPart\"][\"Bytes\"].decode()\n",
    "    last_idx = 0\n",
    "    for match in re.finditer(r'^data:\\s*(.+?)(\\n\\n)', buffer):\n",
    "        try:\n",
    "            chunk = json.loads(match.group(1).strip())\n",
    "            last_idx = match.span()[1]\n",
    "            # print(chunk)\n",
    "            if \"usage\" in chunk:\n",
    "                print(chunk)\n",
    "                input_tokens = chunk[\"usage\"][\"prompt_tokens\"]\n",
    "                output_tokens = chunk[\"usage\"][\"completion_tokens\"]\n",
    "            if \"choices\" in chunk and chunk[\"choices\"][0][\"delta\"][\"content\"]:\n",
    "                if first_token_latency == 0:\n",
    "                    first_token_latency = time.time() - time_start\n",
    "                output.append(chunk[\"choices\"][0][\"delta\"][\"content\"])\n",
    "                print(output[-1], end=\"\", flush=True)\n",
    "\n",
    "        except (json.JSONDecodeError, KeyError, IndexError) as e:\n",
    "            pass\n",
    "    buffer = buffer[last_idx:]\n",
    "\n",
    "\n",
    "total_time = time.time() - time_start\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Input_tokens\", input_tokens, \"Output_tokens\", output_tokens)\n",
    "print(f\"First token latency {first_token_latency:.3} seconds\")\n",
    "print(f\"Output speed {output_tokens/(total_time-first_token_latency):.3} tokens/seconds\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Metrics moniter\n",
    "\n",
    "If you are doing pressure test, you can view vLLM metrics on [CloudWatch-metrics](https://us-east-2.console.aws.amazon.com/cloudwatch/home?region=us-east-2#metricsV2?graph=~(sparkline~false~view~'timeSeries~stacked~false~region~'us-east-2~stat~'Average~period~1)&query=~'*7b*2faws*2fsagemaker*2fEndpoints*2cEndpointName*2cVariantName*7d)\n",
    "\n",
    "![](./assets/vLLM-metric.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Clean\n",
    "You could delete files using these functions. Uncomment last three lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error deleting endpoint: An error occurred (ValidationException) when calling the DeleteEndpoint operation: Could not find endpoint \"tsbiosky-gemma3-hok-pubg-merge-250409-0436\".\n",
      "Endpoint configuration 'tsbiosky-gemma3-hok-pubg-merge-250409-0653' has been deleted.\n",
      "Model 'tsbiosky-gemma3-hok-pubg-merge-250409-0653' has been deleted.\n"
     ]
    }
   ],
   "source": [
    "def delete_endpoint(endpoint_name):\n",
    "    try:\n",
    "        sagemaker_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "        print(f\"Endpoint '{endpoint_name}' deletion initiated.\")\n",
    "\n",
    "        # Wait for the endpoint to be deleted\n",
    "        while True:\n",
    "            try:\n",
    "                sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "                print(\"Waiting for endpoint to be deleted...\")\n",
    "                time.sleep(30)\n",
    "            except sagemaker_client.exceptions.ClientError:\n",
    "                print(f\"Endpoint '{endpoint_name}' has been deleted.\")\n",
    "                break\n",
    "    except sagemaker_client.exceptions.ClientError as e:\n",
    "        print(f\"Error deleting endpoint: {e}\")\n",
    "\n",
    "def delete_endpoint_config(endpoint_config_name):\n",
    "    try:\n",
    "        sagemaker_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "        print(f\"Endpoint configuration '{endpoint_config_name}' has been deleted.\")\n",
    "    except sagemaker_client.exceptions.ClientError as e:\n",
    "        print(f\"Error deleting endpoint configuration: {e}\")\n",
    "\n",
    "def delete_model(model_name):\n",
    "    try:\n",
    "        sagemaker_client.delete_model(ModelName=model_name)\n",
    "        print(f\"Model '{model_name}' has been deleted.\")\n",
    "    except sagemaker_client.exceptions.ClientError as e:\n",
    "        print(f\"Error deleting model: {e}\")\n",
    "\n",
    "\n",
    "delete_endpoint(endpoint_name)\n",
    "delete_endpoint_config(endpoint_config_name)\n",
    "delete_model(endpoint_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
